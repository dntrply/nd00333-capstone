{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "name": "Copy of automl.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIFBchG8DIzE"
      },
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrM_0OmdCtYp"
      },
      "source": [
        "[Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598423888013
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "T1gyC_4iDIzI"
      },
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute.amlcompute import AmlCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.run import Run\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from azureml.pipeline.core.pipeline import Pipeline\n",
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.pipeline.core import TrainingOutput\n",
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.pipeline.steps.automl_step import AutoMLStep\n",
        "\n",
        "from azureml.train.automl.automlconfig import AutoMLConfig\n",
        "from azureml.data import TabularDataset\n",
        "from azureml.widgets.run_details import RunDetails\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import requests\n",
        "\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W17Lc6bYDaPo"
      },
      "source": [
        "CAPSTONE_FOLDER = 'capstone-ml'\n",
        "CAPSTONE_DEBUG_LOG = 'capstone-ml.log'\n",
        "CAPSTONE_LABEL_COLUMN_NAME = 'y'\n",
        "\n",
        "CAPSTONE_AUTOMLSTEP_NAME = 'AutoML Training Step'\n",
        "\n",
        "CAPSTONE_EXPERIMENT_NAME_AUTOML = 'exp-capstone-automl'\n",
        "CAPSTONE_EXPERIMENT_NAME_STEP7 = 'exp-capstone-step7'\n",
        "CAPSTONE_TABULAR_WINE_DATA = 'https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/wine_train.csv'\n",
        "CAPSTONE_DATASET_NAME = 'White Wine Data'\n",
        "CAPSTONE_DATASET_DESCRIPTION = 'Wine data - does the wine taste good?'\n",
        "\n",
        "CAPSTONE_DEPLOYED_MODEL_NAME = 'wine-taste-automl'\n",
        "CAPSTONE_DEPLOYED_MODEL_PATH = './outputs/best_automl.pkl'\n",
        "\n",
        "CAPSTONE_PIPELINEDATA_METRICS_NAME = 'PipelineData_Metrics' \n",
        "CAPSTONE_PIPELINEDATA_MODEL_NAME = 'PipelineData_Model' \n",
        "CAPSTONE_PIPELINE_OUTPUT_METRICS_NAME = 'Pipeline Metrics Output' \n",
        "CAPSTONE_PIPELINE_OUTPUT_MODEL_NAME = 'Pipeline Model Output' \n",
        "CAPSTONE_PIPELINE_DESCRIPTION = 'AutoML Pipeline to train model on the wine data'\n",
        "CAPSTONE_EXPERIMENT_NAME = 'AutoML Train Wine Data Experiment'\n",
        "CAPSTONE_ENV_SERVICE = 'capstone-env-service'\n",
        "\n",
        "CAPSTONE_PUBLISHED_PIPELINE_NAME = 'Wine Data Training Pipeline'\n",
        "CAPSTONE_PUBLISHED_PIPELINE_DESCRIPTION = 'This pipeline trains on the Wine Data'\n",
        "CAPSTONE_PUBLISHED_PIPELINE_VERSION='1.0'\n",
        "\n",
        "CAPSTONE_CONSUME_PIPELINE_ENDPOINT_EXPERIMENT = 'exp-run-pipeline' #\n",
        "\n",
        "CC_NAME = \"CPU-CC\"  # CPU Compute Cluster\n",
        "CURATED_ENV_NAME = 'AzureML-Tutorial'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXX3ww9_DIzJ"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "This machine learning program detects the wine quality of white wine.\n",
        "The task is to determine if the wine is tasty or not.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598423890461
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "axbCq54eDIzK"
      },
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = CAPSTONE_EXPERIMENT_NAME_AUTOML\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCvxfM_3ElcZ"
      },
      "source": [
        "# Next, let's use if it exists, or create if required, a compute cluster to be used by the ML\n",
        "\n",
        "# Access the compute cluster. If it exists, we will have the compute object. \n",
        "# If it does not exist, an exception will be thrown upon which the compute cluster is created\n",
        "try:\n",
        "    cc = ComputeTarget(workspace=ws, name=CC_NAME)\n",
        "    print(f'Compute Cluster target exists and we have a handle to the same')\n",
        "except ComputeTargetException:\n",
        "    # Failed to obtain the compute cluster object\n",
        "    # In all likelihood, a compute cluster of that name has not been created\n",
        "    # Attempt to create the compute cluster\n",
        "    # First set up the configuration\n",
        "\n",
        "    # Specify the configuration of the compute cluster\n",
        "    cc_cfg = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_v2', min_nodes=1, max_nodes=6)\n",
        "    cc = ComputeTarget.create(workspace=ws, name=CC_NAME, provisioning_configuration=cc_cfg)\n",
        "\n",
        "# At this point - we have access to the compute cluster object. Wait for the compute target to complete provisioing\n",
        "cc.wait_for_completion(show_output='True')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifhLxyqqFCtQ"
      },
      "source": [
        "# grab the data and create a dataset\n",
        "# See if the dataset already exists - if so, skip the Dataset creation pieces\n",
        "data_uri = CAPSTONE_TABULAR_WINE_DATA\n",
        "\n",
        "ds_name = CAPSTONE_DATASET_NAME\n",
        "dsets = ws.datasets.keys()\n",
        "\n",
        "if ds_name in dsets:\n",
        "    # dataset exists\n",
        "    proj_ds = dsets[ds_name]\n",
        "else:\n",
        "    # Data set not found. Must create it\n",
        "    proj_ds = Dataset.Tabular.from_delimited_files(data_uri)\n",
        "    # Register the dataset so that on repeated runs, the data does not have to be fetched evey time\n",
        "    proj_ds = proj_ds.register(workspace=ws, name=ds_name, description=CAPSTONE_DATASET_DESCRIPTION)\n",
        "\n",
        "# Take a peek at the data by converting the same to a Pandas dataframe\n",
        "proj_df = proj_ds.to_pandas_dataframe()\n",
        "\n",
        "# print the data\n",
        "proj_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaXlY6KqFVQT"
      },
      "source": [
        "proj_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scO2RZk_DIzL"
      },
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598429217746
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "uJJWKay5DIzL"
      },
      "source": [
        "# TODO: Put your automl settings here\n",
        "\n",
        "automl_settings = {\n",
        "    \"iterations\" : 20,\n",
        "    \"experiment_timeout_minutes\" : 30,\n",
        "    \"enable_early_stopping\" : True,\n",
        "    \"iteration_timeout_minutes\" : 5,\n",
        "    \"max_concurrent_iterations\" : 5,\n",
        "    \"max_cores_per_iteration\" : -1,\n",
        "    \"n_cross_validations\" : 3,\n",
        "    \"primary_metric\" : 'AUC_weighted',\n",
        "    \"verbosity\" : logging.INFO,\n",
        "}\n",
        "\n",
        "# Provide the remainder of the settings/configuration\n",
        "# Note that we are not providing a validation data set - and we may need to\n",
        "# \n",
        "\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    compute_target = cc,\n",
        "    task='classification',\n",
        "    training_data=proj_ds,\n",
        "    label_column_name=CAPSTONE_LABEL_COLUMN_NAME,\n",
        "    path=CAPSTONE_FOLDER,\n",
        "    featurization='auto',\n",
        "    model_explainability=True,\n",
        "    debug_log=CAPSTONE_DEBUG_LOG,\n",
        "    **automl_settings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431107951
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "qm0n8PgRDIzM"
      },
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR49YIwPDIzN"
      },
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431121770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "_lbzZ9SZDIzN"
      },
      "source": [
        "RunDetails(remote_run).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skd-RNClDIzO"
      },
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzVGP_K4Imqr"
      },
      "source": [
        "def print_model(model, prefix=\"\"):\n",
        "    for step in model.steps:\n",
        "        print(prefix + step[0])\n",
        "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
        "            pprint({'estimators': list(e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
        "            print()\n",
        "            for estimator in step[1].estimators:\n",
        "                print_model(estimator[1], estimator[0]+ ' - ')\n",
        "        elif hasattr(step[1], '_base_learners') and hasattr(step[1], '_meta_learner'):\n",
        "            print(\"\\nMeta Learner\")\n",
        "            pprint(step[1]._meta_learner)\n",
        "            print()\n",
        "            for estimator in step[1]._base_learners:\n",
        "                print_model(estimator[1], estimator[0]+ ' - ')\n",
        "        else:\n",
        "            pprint(step[1].get_params())\n",
        "            print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "bPGTZ5shDIzP"
      },
      "source": [
        "automl_best_run, automl_best_model = automlremote_run.get_output()\n",
        "\n",
        "print(f'********** Best AutoML accuracy: {automl_best_run_metrics.get(\"accuracy\")}')\n",
        "print(f'********** printing Best AutoML run:\\n{automl_best_run}\\n\\nPrinting model:')\n",
        "\n",
        "print_model(automl_best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "fNc1risDDIzP"
      },
      "source": [
        "#TODO: Save the best model\n",
        "joblib.dump(automl_best_model, './outputs/automl_model.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otKptwQ9DIzQ"
      },
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Jnovv2OXDIzQ"
      },
      "source": [
        "# Refer - https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python\n",
        "\n",
        "# Tutorial: Deploy an image classification model in Azure Container Instances -\n",
        "# https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-deploy-models-with-aml\n",
        "\n",
        "# Register the model\n",
        "model = automl_best_run.register_model(model_name=CAPSTONE_DEPLOYED_MODEL_NAME, \n",
        "                                       model_path='CAPSTONE_DEPLOYED_MODEL_PATH')\n",
        "\n",
        "\n",
        "curated_env_name = CURATED_ENV_NAME\n",
        "curated_env = Environment.get(workspace=ws, name=curated_env_name)\n",
        "\n",
        "\n",
        "# Possibly create an inference config\n",
        "\n",
        "env = Environment(name=\"capstone_environment\")\n",
        "inference_config = InferenceConfig(\n",
        "    environment=curated_env,\n",
        "    entry_script=\"score.py\",\n",
        ")\n",
        "\n",
        "\n",
        "service_name = CAPSTONE_ENV_SERVICE\n",
        "\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=service_name,\n",
        "                       models=[automl_best_model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "8KBf-4m2DIzR"
      },
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dJNveHvSDIzR"
      },
      "source": [
        "# To enable ApplicationInsights on the service (webservice), \n",
        "# * first access the endpoint using the name assigned at the time of deployment\n",
        "# * next update webservice parameters such as enabling application insights (enable_app_insights)\n",
        "\n",
        "proj_webservice = Webservice(\n",
        "    workspace = ws,\n",
        "    name=CAPSTONE_DEPLOYED_MODEL_NAME\n",
        ")\n",
        "\n",
        "proj_webservice.update(\n",
        "    enable_app_insights=True\n",
        ")\n",
        "\n",
        "# At this point application insights (logging is enabled) and can be\n",
        "# checked in the GUI in AutoML studio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la5hi2gjwGg9"
      },
      "source": [
        "# URL for the web service, should be similar to:\n",
        "# 'http://8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io/score'\n",
        "\n",
        "# From the tail end of the code at\n",
        "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python\n",
        "# - Deploy machine learning models to Azure\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "service = Webservice(workspace=ws, name=\"CAPSTONE_ENV_SERVICE\")\n",
        "scoring_uri = service.scoring_uri\n",
        "\n",
        "# If the service is authenticated, set the key or token\n",
        "key, _ = service.get_keys()\n",
        "\n",
        "# Set the appropriate headers\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
        "\n",
        "# Make the request and display the response and logs\n",
        "data = {\n",
        "    \"query\": \"What color is the fox\",\n",
        "    \"context\": \"The quick brown fox jumped over the lazy dog.\",\n",
        "}\n",
        "data = json.dumps(data)\n",
        "resp = requests.post(scoring_uri, data=data, headers=headers)\n",
        "print(resp.text)\n",
        "\n",
        "\n",
        "fixed ac\t   volatile ac\tcitric acid\t  residual sugar\tchlorides\t  free sulfurdi\ttotal sulfurdi\tdensity\t       pH\t        sulphates\t    alcohol\tquality\t\t\n",
        "0.883090875\t0.3150853064\t-0.5304215055\t-0.1166025484\t-0.447289012\t-0.7237011554\t-0.6908704601\t-0.01249670459\t1.004852702\t0.4394546089\t0.3947056997\t0\t\t\n",
        "0.7645889612\t1.307202455\t-0.8609459206\t1.657825186\t0.3765862299\t-0.4297069397\t0.8386109571\t1.655893566\t-0.05474573919\t0.001341709573\t-0.6616718988\t0\t\t\n",
        "0.883090875\t0.3150853064\t-0.5304215055\t-0.1166025484\t-0.447289012\t-0.7237011554\t-0.6908704601\t-0.01249670459\t1.004852702\t0.4394546089\t0.3947056997\t0\t\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Two sets of data to score, so we get two results back\n",
        "data = {\"data\":\n",
        "        [\n",
        "          {\n",
        "            \"fixed acidity\": 0.883090875,\n",
        "            \"volatile acidity\": \"0.3150853064\",\n",
        "            \"citric acid\": \"-0.5304215055\",\n",
        "            \"residual sugar\": \"-0.1166025484\",\n",
        "            \"chlorides\": \"-0.447289012\",\n",
        "            \"free sulfur dioxide\": \"-0.7237011554\",\n",
        "            \"total sulfur dioxide\": \"-0.6908704601\",\n",
        "            \"density\": \"-0.01249670459\",\n",
        "            \"pH\": \"1.004852702\",\n",
        "            \"sulphates\": \"0.4394546089\",\n",
        "            \"alcohol\": 0.3947056997,\n",
        "          },\n",
        "          {\n",
        "            \"fixed acidity\": 0.7645889612,\n",
        "            \"volatile acidity\": \"1.307202455\",\n",
        "            \"citric acid\": \"-0.8609459206\",\n",
        "            \"residual sugar\": \"1.657825186\",\n",
        "            \"chlorides\": \"0.3765862299\",\n",
        "            \"free sulfur dioxide\": \"-0.4297069397\",\n",
        "            \"total sulfur dioxide\": \"0.8386109571\",\n",
        "            \"density\": \"1.655893566\",\n",
        "            \"pH\": \"-0.05474573919\",\n",
        "            \"sulphates\": \"0.001341709573\",\n",
        "            \"alcohol\": 0.3947056997,\n",
        "          },\n",
        "      ]\n",
        "    }\n",
        "# Convert to JSON string\n",
        "input_data = json.dumps(data)\n",
        "with open(\"data.json\", \"w\") as _f:\n",
        "    _f.write(input_data)\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "# If authentication is enabled, set the authorization header\n",
        "headers['Authorization'] = f'Bearer {key}'\n",
        "\n",
        "# Make the request and display the response\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "print(resp.json())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "QkENqomcDIzR"
      },
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "1trRJIbbDIzS"
      },
      "source": [
        "logs = proj_webservice.get_logs()\n",
        "\n",
        "for line in logs.split('\\n'):\n",
        "    print(line)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhRicHU1gkEM"
      },
      "source": [
        "# Clean up any resources\n",
        "# Delete the Webservice\n",
        "# delete the compute cluster\n",
        "\n",
        "proj_webservice.delete()\n",
        "cc.delete()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLk4oZDIDIzS"
      },
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqcD2kWygoY1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaRTmB9VDIzT"
      },
      "source": [
        ""
      ]
    }
  ]
}