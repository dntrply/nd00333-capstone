{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "name": "current automl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIFBchG8DIzE"
      },
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635430269301
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "T1gyC_4iDIzI"
      },
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute.amlcompute import AmlCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.run import Run\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core.model import Model\n",
        "\n",
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from azureml.pipeline.core.pipeline import Pipeline\n",
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.pipeline.core import TrainingOutput\n",
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.pipeline.steps.automl_step import AutoMLStep\n",
        "\n",
        "from azureml.train.automl.automlconfig import AutoMLConfig\n",
        "from azureml.data import TabularDataset\n",
        "from azureml.widgets.run_details import RunDetails\n",
        "\n",
        "from azureml.automl.core.shared import constants\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import requests\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import logging\n",
        "import joblib\n",
        "\n",
        "from train import clean_data, get_dataset\n",
        "import capstone_constants as c_constants\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW25hNLHkeop"
      },
      "source": [
        "TABULAR_BREAST_CANCER_DATA_URI = 'https://github.com/dntrply/nd00333-capstone/blob/master/dataset/Breast_cancer_data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXX3ww9_DIzJ"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "Dat:[ Breast Cancer Prediction Dataset](https://www.kaggle.com/merishnasuwal/breast-cancer-prediction-dataset)\n",
        "\n",
        "This machine learning program detects the presence (or absence) of breast cancer from pertinent data regarding physical characteristics.\n",
        "An understanding of the data can be had at https://www.kaggle.com/merishnasuwal/breast-cancer-prediction-dataset/discussion/66975#509394\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external.\n",
        "\n",
        "The dataset is external. It is manually downloaded as a csv and then uploaded to a publicly acccessible github account:\n",
        "'https://github.com/dntrply/nd00333-capstone/blob/master/dataset/Breast_cancer_data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg7_8cowjtZX"
      },
      "source": [
        "ds = TabularDatasetFactory.from_delimited_files(https://github.com/dntrply/nd00333-capstone/blob/master/dataset/Breast_cancer_data.csv)\n",
        "df = ds.to_pandas_dataframe()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQo3pTJGlxVI"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOPDxM9pASpB"
      },
      "source": [
        "# Split the dtaaset so that a small fraction may be used for prediction\n",
        "train_ds, _ = ds.random_split(percentage=99, seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCvxfM_3ElcZ",
        "gather": {
          "logged": 1635430409044
        }
      },
      "source": [
        "# Next, let's use if it exists, or create if required, a compute cluster to be used by the ML\n",
        "\n",
        "# Access the compute cluster. If it exists, we will have the compute object. \n",
        "# If it does not exist, an exception will be thrown upon which the compute cluster is created\n",
        "try:\n",
        "    cc = ComputeTarget(workspace=ws, name='COMPUTE-CLUSTER-AUTOML')\n",
        "except ComputeTargetException:\n",
        "    # Failed to obtain the compute cluster object\n",
        "    # In all likelihood, a compute cluster of that name has not been created\n",
        "    # Attempt to create the compute cluster\n",
        "    # First set up the configuration\n",
        "\n",
        "    # Specify the configuration of the compute cluster\n",
        "    cc_cfg = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_v2', min_nodes=1, max_nodes=6)\n",
        "    cc = ComputeTarget.create(workspace=ws, name='COMPUTE-CLUSTER-AUTOML', provisioning_configuration=cc_cfg)\n",
        "\n",
        "# At this point - we have access to the compute cluster object. Wait for the compute target to complete provisioing\n",
        "cc.wait_for_completion(show_output='True')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635430271016
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "axbCq54eDIzK"
      },
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment=Experiment(ws, 'experiment-capstone-automl')  // Experiment name in Azure ML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scO2RZk_DIzL"
      },
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
        "\n",
        "This project is a classification issue. More so, it is a binary classification issue as teh outcome is whether the wine is of a good quality or not.\n",
        "\n",
        "AUC_weighted is an apporpriate metric to target for a binary classification.\n",
        "[Set up AutoML training with Python](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train)\n",
        "\n",
        "It is generally recommended to enable early stopping as it is possible that after a while no further improvement in the model is feasible.\n",
        "\n",
        "There is enrally limited to no benefit to using a large number of cross validations. In this instance, we have set it to 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635430416504
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "uJJWKay5DIzL"
      },
      "source": [
        "# TODO: Put your automl settings here\n",
        "\n",
        "automl_settings = {\n",
        "    \"iterations\" : 20,\n",
        "    \"experiment_timeout_minutes\" : 30,\n",
        "    \"enable_early_stopping\" : True,\n",
        "    \"iteration_timeout_minutes\" : 5,\n",
        "    \"max_concurrent_iterations\" : 5,\n",
        "    \"max_cores_per_iteration\" : -1,\n",
        "    \"n_cross_validations\" : 3,\n",
        "    \"primary_metric\" : 'AUC_weighted',\n",
        "    \"verbosity\" : logging.INFO,\n",
        "}\n",
        "\n",
        "# Provide the remainder of the settings/configuration\n",
        "# Note that we are not providing a validation data set\n",
        "# \n",
        "\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    compute_target = cc,\n",
        "    task='classification',\n",
        "    training_data=train_ds,\n",
        "    label_column_name='diagnosis',\n",
        "    featurization='auto',\n",
        "    model_explainability=True,\n",
        "    debug_log='capstone_automl.log',\n",
        "    **automl_settings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635430423241
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "qm0n8PgRDIzM"
      },
      "source": [
        "# TODO: Submit your experiment\n",
        "automl_run = experiment.submit(automl_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR49YIwPDIzN"
      },
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635430423742
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "_lbzZ9SZDIzN"
      },
      "source": [
        "RunDetails(automl_run).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635431089803
        },
        "id": "ah8Hq8NCNMY4"
      },
      "source": [
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skd-RNClDIzO"
      },
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzVGP_K4Imqr",
        "gather": {
          "logged": 1635431090444
        }
      },
      "source": [
        "def print_model(model, prefix=\"\"):\n",
        "    for step in model.steps:\n",
        "        print(prefix + step[0])\n",
        "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
        "            pprint({'estimators': list(e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
        "            print()\n",
        "            for estimator in step[1].estimators:\n",
        "                print_model(estimator[1], estimator[0]+ ' - ')\n",
        "        elif hasattr(step[1], '_base_learners') and hasattr(step[1], '_meta_learner'):\n",
        "            print(\"\\nMeta Learner\")\n",
        "            pprint(step[1]._meta_learner)\n",
        "            print()\n",
        "            for estimator in step[1]._base_learners:\n",
        "                print_model(estimator[1], estimator[0]+ ' - ')\n",
        "        else:\n",
        "            pprint(step[1].get_params())\n",
        "            print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635431114251
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "bPGTZ5shDIzP"
      },
      "source": [
        "automl_best_run, automl_best_model = automl_run.get_output()\n",
        "\n",
        "automl_best_run_metrics = automl_best_run.get_metrics()\n",
        "\n",
        "print(f'********** Best AutoML accuracy: {automl_best_run_metrics.get(\"accuracy\")}')\n",
        "print(f'********** printing Best AutoML run:\\n{automl_best_run}\\n\\nPrinting model:')\n",
        "\n",
        "print_model(automl_best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635431117028
        },
        "id": "vm6pVYDewoKt"
      },
      "source": [
        "print(automl_run.get_metrics())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635432546017
        },
        "id": "GO9oXlW-NMY6"
      },
      "source": [
        "# Create the outputs directory\n",
        "if 'outputs' not in os.listdir():\n",
        "    os.mkdir('outputs'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635432720386
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "fNc1risDDIzP"
      },
      "source": [
        "#TODO: Save the best model\n",
        "joblib.dump(automl_best_model, os.path.join('outputs','best_automl.pkl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhf4ImWV83Gg",
        "gather": {
          "logged": 1635433128179
        }
      },
      "source": [
        "# download the scoring file and the environmrnt file\n",
        "\n",
        "automl_best_run.download_file(constants.SCORING_FILE_PATH, os.path.join('outputs', 'scoring.py'))\n",
        "automl_best_run.download_file(constants.CONDA_ENV_FILE_PATH, os.path.join('outputs', 'best_run_environment.yml'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otKptwQ9DIzQ"
      },
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635434441586
        },
        "id": "yI5F2zyXNMY9"
      },
      "source": [
        "# Refer - https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python\n",
        "\n",
        "# Tutorial: Deploy an image classification model in Azure Container Instances -\n",
        "# https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-deploy-models-with-aml\n",
        "\n",
        "# Register the model\n",
        "# registered_model = automl_run.register_model(model_name='wine-taste-automl', description=c_constants.DEPLOYED_AUTOML_MODEL_DESCRIPTION)\n",
        "registered_model = automl_best_run.register_model(model_path=constants.MODEL_PATH, \n",
        "                                                model_name='breast-cancer-automl', \n",
        "                                                description='Breast Cancer detection using Azure AutoML',\n",
        "                                                tags={'Method of execution':'AutoML'},\n",
        "                                                properties={'Accuracy':automl_best_run_metrics['accuracy']})\n",
        "print(f'{automl_run.model_id}')\n",
        "print(f'{registered_model.name}  {registered_model.id}  {registered_model.version}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635434690326
        },
        "id": "gxaQkASwNMY_"
      },
      "source": [
        "# Anytime as necessary, access the registered model\n",
        "retrieved_model = Model(workspace=ws, name='breast-cancer-automl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635435114357
        },
        "id": "t3QpRDuCNMZA"
      },
      "source": [
        "# Create an inference config\n",
        "\n",
        "inference_config = InferenceConfig(\n",
        "    environment=Environment.from_conda_specification(name='myenv', file_path=os.path.join('outputs', 'best_run_env.yml')),\n",
        "    source_directory='outputs',\n",
        "    entry_script='best_run_environment.yml',\n",
        ")\n",
        "\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1635122866252
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Jnovv2OXDIzQ"
      },
      "source": [
        "\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name='breast-cancer-service',\n",
        "                       models=[retrieved_model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635120119986
        },
        "id": "CN5yjDX1NMZB"
      },
      "source": [
        "logs = service.get_logs()\n",
        "\n",
        "for line in logs.split('\\n'):\n",
        "    print(line)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "8KBf-4m2DIzR"
      },
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dJNveHvSDIzR"
      },
      "source": [
        "# To enable ApplicationInsights on the service (webservice), \n",
        "# * first access the endpoint using the name assigned at the time of deployment\n",
        "# * next update webservice parameters such as enabling application insights (enable_app_insights)\n",
        "\n",
        "webservice = Webservice(\n",
        "    workspace = ws,\n",
        "    name='breast-cancer-service'\n",
        ")\n",
        "\n",
        "webservice.update(\n",
        "    enable_app_insights=True\n",
        ")\n",
        "\n",
        "# At this point application insights (logging is enabled) and can be\n",
        "# checked in the GUI in AutoML studio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la5hi2gjwGg9"
      },
      "source": [
        "# URL for the web service, should be similar to:\n",
        "# 'http://8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io/score'\n",
        "\n",
        "# From the tail end of the code at\n",
        "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python\n",
        "# - Deploy machine learning models to Azure\n",
        "\n",
        "\n",
        "scoring_uri = webservice.scoring_uri\n",
        "\n",
        "# If the service is authenticated, set the key or token\n",
        "key, _ = webservice.get_keys()\n",
        "\n",
        "# Set the appropriate headers\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
        "\n",
        "# retrieve the data for predictions\n",
        "all_ds = TabularDatasetFactory.from_delimited_files(https://github.com/dntrply/nd00333-capstone/blob/master/dataset/Breast_cancer_data.csv)\n",
        ")\n",
        "_, predict_ds = all_ds.random_split(percentage=99, seed=42)\n",
        "\n",
        "predict_data = predict_ds.to_pandas_dataframe()\n",
        "predict_label = predict_data.pop('diagnosis')\n",
        "\n",
        "\n",
        "# Convert to JSON string\n",
        "tstdatahomic2018 = json.dumps({'data': tsthomic2018.to_dict(orient='records')})\n",
        "\n",
        "score_data = json.dumps({'data': predict_data.to_dict(orient='records')})\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "# If authentication is enabled, set the authorization header\n",
        "headers['Authorization'] = f'Bearer {key}'\n",
        "\n",
        "# Make the request and display the predictions\n",
        "resp = requests.post(scoring_uri, score_data, headers=headers)\n",
        "print(f'{resp.json()}')\n",
        "\n",
        "# Print the actual diagnosis\n",
        "print(f'{predict_label}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "QkENqomcDIzR"
      },
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "1trRJIbbDIzS"
      },
      "source": [
        "logs = webservice.get_logs()\n",
        "\n",
        "for line in logs.split('\\n'):\n",
        "    print(line)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhRicHU1gkEM"
      },
      "source": [
        "# Clean up any resources\n",
        "# Delete the Webservice\n",
        "# delete the compute cluster\n",
        "\n",
        "webservice.delete()\n",
        "cc.delete()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLk4oZDIDIzS"
      },
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqcD2kWygoY1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaRTmB9VDIzT"
      },
      "source": [
        ""
      ]
    }
  ]
}